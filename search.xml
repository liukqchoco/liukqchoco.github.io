<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>洛谷手记</title>
      <link href="/2024/10/07/%E6%B4%9B%E8%B0%B7%E6%89%8B%E8%AE%B0/"/>
      <url>/2024/10/07/%E6%B4%9B%E8%B0%B7%E6%89%8B%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> DS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Revisiting_ML</title>
      <link href="/2024/10/07/Revisiting_ML/"/>
      <url>/2024/10/07/Revisiting_ML/</url>
      
        <content type="html"><![CDATA[<h1 id="Revisiting-ML"><a href="#Revisiting-ML" class="headerlink" title="Revisiting ML"></a>Revisiting ML</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>对概率的诠释有两大学派，一种是频率派另一种是贝叶斯派。后面我们对观测集采用下面记号：<br>$$<br>X_{N\times p}&#x3D;(x_{1},x_{2},\cdots,x_{N})^{T},x_{i}&#x3D;(x_{i1},x_{i2},\cdots,x_{ip})^{T}<br>$$<br>这个记号表示有 $N$ 个样本，每个样本都是 $p$ 维向量。其中每个观测都是由 $p(x|\theta)$ 生成的。</p><h3 id="频率派的观点"><a href="#频率派的观点" class="headerlink" title="频率派的观点"></a>频率派的观点</h3><p>$p(x|\theta)$中的 $\theta$ 是一个常量。对于 $N$ 个观测来说观测集的概率为 $p(X|\theta)\mathop{&#x3D;}\limits _{iid}\prod\limits <em>{i&#x3D;1}^{N}p(x</em>{i}|\theta)$ 。为了求 $\theta$ 的大小，我们采用最大对数似然MLE的方法：</p><p>$$<br>\theta_{MLE}&#x3D;\mathop{argmax}\limits _{\theta}\log p(X|\theta)\mathop{&#x3D;}\limits _{iid}\mathop{argmax}\limits _{\theta}\sum\limits <em>{i&#x3D;1}^{N}\log p(x</em>{i}|\theta)<br>$$</p><h3 id="贝叶斯派的观点"><a href="#贝叶斯派的观点" class="headerlink" title="贝叶斯派的观点"></a>贝叶斯派的观点</h3><p>贝叶斯派认为 $p(x|\theta)$ 中的 $\theta$ 不是一个常量。这个 $\theta$ 满足一个预设的先验的分布 $\theta\sim p(\theta)$ 。于是根据贝叶斯定理依赖观测集参数的后验可以写成：</p><p>$$<br>p(\theta|X)&#x3D;\frac{p(X|\theta)\cdot p(\theta)}{p(X)}&#x3D;\frac{p(X|\theta)\cdot p(\theta)}{\int\limits _{\theta}p(X|\theta)\cdot p(\theta)d\theta}<br>$$<br>为了求 $\theta$ 的值，我们要最大化这个参数后验MAP：</p><p>$$<br>\theta_{MAP}&#x3D;\mathop{argmax}\limits _{\theta}p(\theta|X)&#x3D;\mathop{argmax}\limits _{\theta}p(X|\theta)\cdot p(\theta)<br>$$<br>其中第二个等号是由于分母和 $\theta$ 没有关系。求解这个 $\theta$ 值后计算$\frac{p(X|\theta)\cdot p(\theta)}{\int\limits <em>{\theta}p(X|\theta)\cdot p(\theta)d\theta}$ ，就得到了参数的后验概率。其中 $p(X|\theta)$ 叫似然，是我们的模型分布。得到了参数的后验分布后，我们可以将这个分布用于预测贝叶斯预测：<br>$$<br>p(x</em>{new}|X)&#x3D;\int\limits <em>{\theta}p(x</em>{new}|\theta)\cdot p(\theta|X)d\theta<br>$$<br>其中积分中的被乘数是模型，乘数是后验分布。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>频率派和贝叶斯派分别给出了一系列的机器学习算法。频率派的观点导出了一系列的统计机器学习算法而贝叶斯派导出了概率图理论。在应用频率派的 MLE 方法时最优化理论占有重要地位。而贝叶斯派的算法无论是后验概率的建模还是应用这个后验进行推断时积分占有重要地位。因此采样积分方法如 MCMC 有很多应用。</p><h2 id="Math"><a href="#Math" class="headerlink" title="Math"></a>Math</h2><h3 id="先验、后验与似然概率"><a href="#先验、后验与似然概率" class="headerlink" title="先验、后验与似然概率"></a>先验、后验与似然概率</h3><p>属于<strong>朴素贝叶斯</strong>（Naive Bayes）相关概念</p><p><strong>1、先验概率(prior probability)</strong></p><p>百度百科：先验概率（prior probability）是指<strong>根据以往经验和分析得到的概率</strong>，如全概率公式，它往往作为“由因求果”问题中的“因”出现的概率。</p><p>维基百科：在贝叶斯统计中，某一不确定量p的先验概率（prior probability）分布是<strong>在考虑“观测数据”前，能表达p不确定性的概率分布</strong>。它旨在描述这个不确定量的不确定程度，而不是这个不确定量的随机性。这个不确定量可以是一个参数，或者是一个隐含变量（英语：latent variable）。</p><p>我们可以发现这两个定义有一个共同点，即<strong>先验概率是不依靠观测数据的概率分布</strong>，也就是与其他因素独立的分布。在<a href="https://so.csdn.net/so/search?q=%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF&spm=1001.2101.3001.7020">朴素贝叶斯</a>中，<strong>类别c的概率就是先验概率，表示为$P(C)$。</strong></p><p><strong>2、后验概率(posterior probability)</strong></p><p>百度百科：后验概率是指<strong>在得到“结果”的信息后重新修正的概率</strong>，是“执果寻因”问题中的”果”。</p><p>维基百科：在贝叶斯统计中，一个随机事件或者一个不确定事件的后验概率（posterior probability）是在考虑和给出相关证据或数据后所得到的条件概率。同样，后验概率分布是一个未知量（视为随机变量）基于试验和调查后得到的概率分布。“后验”在本文中代表考虑了被测试事件的相关证据。</p><p>在朴素贝叶斯中，<strong>后验概率指给定数据x后，类别<img src="https://latex.csdn.net/eq?c%5Cin%20C" alt="c\in C">的概率<img src="https://latex.csdn.net/eq?P(c%20%7C%20x)" alt="P(c | x)">。</strong></p><p>先验概率与后验概率有不可分割的联系，后验概率的计算要以先验概率为基础。<strong>事情还没有发生，要求这件事情发生的可能性的大小，是先验概率。事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小，是后验概率。</strong></p><p><strong>3、似然概率(likelihood)</strong></p><p>百度百科：统计学中，似然函数是一种关于统计模型参数的函数。<strong>给定输出$x$时，关于参数<img src="https://latex.csdn.net/eq?%5Ctheta" alt="\theta">的似然函数 <img src="https://latex.csdn.net/eq?L(%5Ctheta%7Cx)" alt="L(\theta|x)">（在数值上）等于给定参数<img src="https://latex.csdn.net/eq?%5Ctheta" alt="\theta">后变量X的概率：<img src="https://latex.csdn.net/eq?L(%5Ctheta%7Cx)=P(X=x%7C%5Ctheta)" alt="L(\theta|x)=P(X=x|\theta)">。</strong></p><p>维基百科：在数理统计学中，似然函数（英语：likelihood function）是一种关于统计模型中的参数的函数，表示模型参数中的似然性（英语：likelihood）。</p><p>似然概率其实很好理解，就是说我们现在有一堆数据，现在需要构建一组参数对这些数据建模，以使得模型能够尽可能地拟合这些数据。所以我们要做的就是从很多组参数中选出一组使得模型对数据的拟合程度最高，所以也常常说最大似然概率。</p><p>注意“似然”与“概率”意思相近，都是指某种事件发生的可能性，但是在统计学中，“似然”和“概率”又有明确的区分：</p><ul><li><strong>“概率”描述了给定模型参数后，描述结果的合理性，而不涉及任何观察到的数据</strong></li><li><strong>“似然”描述了给定了特定观测值后，描述模型参数是否合理</strong></li></ul><p>举个栗子，抛一枚均匀的硬币，拋20次，问15次拋得正面的可能性有多大？这里的可能性就是“概率”；而拋一枚硬币，拋20次，结果15次正面向上，问其为均匀的可能性？这里的可能性就是“似然”。</p><p><strong>4、先验、后验概率与似然之间的关系</strong></p><ul><li>先验概率：<img src="https://latex.csdn.net/eq?P%20(%20c%20)" alt="P ( c )"></li><li>后验概率：<img src="https://latex.csdn.net/eq?P%20(c%7Cx)" alt="P (c|x)"></li><li>似然：<img src="https://latex.csdn.net/eq?P(X=x%7C%5Ctheta%20=c)" alt="P(X=x|\theta =c)"></li></ul><p>存在的关系</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/c8d6c3d64446feba7d8143d0ecc1d85c.png" alt="img"></p><p>一般而言数据X的分布是已知的，因此</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/f586b7b52b252b58fe387526bdc4bc08.png" alt="img"></p><p>此外，当参数<img src="https://latex.csdn.net/eq?%5Ctheta" alt="\theta">是均匀分布时，后验概率与似然概率成正比，即</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/f9be3263524a33ed33ca4dec068776b2.png" alt="img"></p><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p>考虑在一个正态分布中随机抽样，抽样出一组值$X&#x3D;[x_1,x_2,…,x_n]$，这组值独立同分布，都符合某一个正态分布。此时我希望通过这组抽样出来的值（结果）反推出<strong>最有可能抽出这一组结果的原有分布</strong>（参数），这个过程即为似然。</p><p>对于这组抽样出来的值的概率，即为在$\mu,\sigma$的分布$N(\mu,\sigma^2)$下的条件概率。由于他们是相互独立的，那么条件概率即为各个抽样值的概率的连乘：$\max \left[\prod_{i}^{n} \mathcal{N}\left(x_{i} \mid \mu, \sigma\right)\right]$，将其取log即为<strong>对数似然</strong>，所以极大似然估计即为通过求对数似然的最大值，来找到最合适的参数。</p><p>以线性回归举例</p><p>在给定x的情况下，因为y是不确定的，相当于给y增加了一个均值为0的高斯噪声$\epsilon$。<img src="C:\Users\29607\AppData\Roaming\Typora\typora-user-images\image-20241003001600366.png" alt="image-20241003001600366" style="zoom:50%;" /><img src="C:\Users\29607\AppData\Roaming\Typora\typora-user-images\image-20241003001615573.png" alt="image-20241003001615573" style="zoom:50%;" /></p><p>现在y的分布即为一个如图的高斯分布</p><p>在给定散点x，y的情况下，我要求线性回归模型，即求最合适的$w$。这不就是对其做极大似然估计嘛？</p><p>过程如下：</p><p>有极大似然函数：$\sum_{i} \ln \mathcal{N}(y_i | \omega x_i, \sigma^2)$</p><p>概率密度：$f(x) &#x3D; \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2} \left( \frac{x - \mu}{\sigma} \right)^2}$</p><p>最终将噪声的参数部分去掉，仅留下包含w的部分，即为下图，<strong>与最小二乘法的结果完全一致</strong><br>$$<br>\sum_{i&#x3D;1}^{n} - (y_i - \omega x_i)^2<br>$$</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2>]]></content>
      
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/10/07/hello-world/"/>
      <url>/2024/10/07/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>关于</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>音乐</title>
      <link href="/music/index.html"/>
      <url>/music/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>标签</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>电影</title>
      <link href="/movies/index.html"/>
      <url>/movies/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>友链</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
